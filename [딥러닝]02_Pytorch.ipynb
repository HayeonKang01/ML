{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[딥러닝]02_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H4ZbmR1q-UHI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import fetch_openml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml('mnist_784')\n",
        "mnist.data.shape, mnist.target.shape\n",
        "x_data = mnist.data\n",
        "y_data = mnist.target"
      ],
      "metadata": {
        "id": "wa_KwvAB-pI_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_data.shape)\n",
        "print(y_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfgVBIgi-v-8",
        "outputId": "f0ea6381-854b-4425-e49d-b77a74975767"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 784)\n",
            "(70000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_data.iloc[0])\n",
        "print(y_data.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN5ERoSS-ywa",
        "outputId": "c3afee52-6b04-43ca-b18c-228a309fb192"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pixel1      0.0\n",
            "pixel2      0.0\n",
            "pixel3      0.0\n",
            "pixel4      0.0\n",
            "pixel5      0.0\n",
            "           ... \n",
            "pixel780    0.0\n",
            "pixel781    0.0\n",
            "pixel782    0.0\n",
            "pixel783    0.0\n",
            "pixel784    0.0\n",
            "Name: 0, Length: 784, dtype: float64\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(x_data.iloc[0].values.reshape(28,28), cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "LLG6NeNm-17g",
        "outputId": "7e4ccb1d-096d-4a0d-f126-42eb3d27dc2c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f96ef53a190>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkCYTRxD--vZ",
        "outputId": "efa22d5b-573c-434f-9ce3-2e6c8b0d8a4a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56000, 784)\n",
            "(14000, 784)\n",
            "(56000,)\n",
            "(14000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=10, tol=0.0001, penalty='l2', C=1.0)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_train_predict = model.predict(X_train)\n",
        "train_acc = metrics.accuracy_score(y_train, y_train_predict)\n",
        "print(train_acc)\n",
        "\n",
        "y_test_predict = model.predict(X_test)\n",
        "test_acc = metrics.accuracy_score(y_test, y_test_predict)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaWHW0oA_KrC",
        "outputId": "88d91240-9c2a-458e-c16d-f1b069064af4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8824107142857143\n",
            "0.8825714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=100, tol=0.0001, penalty='l2', C=1.0)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_train_predict = model.predict(X_train)\n",
        "train_acc = metrics.accuracy_score(y_train, y_train_predict)\n",
        "print(train_acc)\n",
        "\n",
        "y_test_predict = model.predict(X_test)\n",
        "test_acc = metrics.accuracy_score(y_test, y_test_predict)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI0PUzyA_k7z",
        "outputId": "b52cc30b-4192-4a2b-dfd6-f0969b27d70e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9360892857142857\n",
            "0.9178571428571428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=1000, tol=0.0001, penalty='l2', C=1.0)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_train_predict = model.predict(X_train)\n",
        "train_acc = metrics.accuracy_score(y_train, y_train_predict)\n",
        "print(train_acc)\n",
        "\n",
        "y_test_predict = model.predict(X_test)\n",
        "test_acc = metrics.accuracy_score(y_test, y_test_predict)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87ksjPde_oQz",
        "outputId": "0819a2ec-01c4-4def-e561-51493ea117ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9431428571428572\n",
            "0.9165714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### max_iter를 늘리면 정확도는 더 좋아지지만 나중에는 오버피팅이 일어날 것이다.\n",
        "---\n",
        "# Pytorch"
      ],
      "metadata": {
        "id": "7ylEcLz1_skR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lh25hoz_rT8",
        "outputId": "0fe5262f-3d7f-4e59-fac5-1a81ad353ad3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.10.0+cu111)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor\n",
        "- 하나의 데이터타입을 포함하는 다차원행렬 \n",
        "- Pytorch의 연산 기본단위 \n",
        "- numpy : data / tensor : data + grad, gpu에서 연산가능\n",
        "- grad는 Tensro의 연산을 기억하고 gradient value를 자동으로 계산\n",
        "  * model 학습을 위해서는 각 레이어의 미분값을 알아야 함"
      ],
      "metadata": {
        "id": "ddrGSg77CYji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.zeros(4)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo8Xpkv5COqn",
        "outputId": "ed985609-cfdf-41f7-9bb2-fbe2d99f96d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros([2,3])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAnGet-jC6n0",
        "outputId": "f471e145-3c3d-4a2f-d276-5e9a45a2549c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(4)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq4RsQNFDAVI",
        "outputId": "30efb356-80bb-4487-d8a5-0e72d5bccab0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones([2,3,1])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6khJsqQDCG3",
        "outputId": "19e46699-2e73-40be-e397-0cd53b91b253"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1.],\n",
            "         [1.],\n",
            "         [1.]],\n",
            "\n",
            "        [[1.],\n",
            "         [1.],\n",
            "         [1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "4GNxT3sPDET6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1,2,3], [4,5,6]]\n",
        "x = torch.tensor(data)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq8hwsPTDL5f",
        "outputId": "5bb0ecd9-4c47-4c32-8f5d-2e40532784f4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_arr = np.array([[4,3],[1,3],[5,5]])\n",
        "x = torch.tensor(data_arr)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAys4_1oDPhQ",
        "outputId": "d012add5-451b-441b-90e3-99119d05663e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4, 3],\n",
            "        [1, 3],\n",
            "        [5, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.from_numpy(data_arr)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CuwWUKjDXFP",
        "outputId": "2da659b1-3453-44d7-fcdf-04e81409c03a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4, 3],\n",
            "        [1, 3],\n",
            "        [5, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn([3,5])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz4Yef0mDdf2",
        "outputId": "939ce814-3adf-4f27-cf6b-768d217b9f5d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5861, -1.4275,  0.7065,  0.1544,  0.0442],\n",
            "        [-1.2541, -0.4642,  0.4140, -1.6152, -0.8907],\n",
            "        [ 0.2709, -0.7799,  0.1627,  0.3728, -0.1452]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand([2,3]) # 2행 3열\n",
        "\n",
        "# Attributes of tensor\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")\n",
        "\n",
        "# Standard numpy-like indexing and sclicing\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:,0]}\")\n",
        "print(f\"Last column: {tensor[..., -1]}\")\n",
        "tensor[:,1] = 0 # 두번째 컬럼 값을 모두 0으로 지정\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to721y4hDksv",
        "outputId": "8f90063c-cc2e-426e-aeef-8c6e44ae676c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([2, 3])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n",
            "First row: tensor([0.9716, 0.2431, 0.7750])\n",
            "First column: tensor([0.9716, 0.6953])\n",
            "Last column: tensor([0.7750, 0.9264])\n",
            "tensor([[0.9716, 0.0000, 0.7750],\n",
            "        [0.6953, 0.0000, 0.9264]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "QjiZ9YLfDxKG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Tensor\n",
        "## Directly initializing\n",
        "tensor_one = torch.tensor([[5,8,6],[8,4,5]], dtype=torch.float64, requires_grad=True)\n",
        "\n",
        "# Randomly initializing tensor with shape of [2,3]\n",
        "tensor_two = torch.randn([2,3], dtype=torch.float64, requires_grad=True)\n",
        "print(tensor_one)\n",
        "print(tensor_two, '\\n')\n",
        "\n",
        "## Arithmetic operations\n",
        "y1 = torch.add(tensor_one, tensor_two)\n",
        "y2 = tensor_one + tensor_two\n",
        "print(y1)\n",
        "print(y2, '\\n')\n",
        "\n",
        "y1 = torch.mul(tensor_one, tensor_two)\n",
        "y2 = tensor_one * tensor_two\n",
        "print(y1)\n",
        "print(y2, '\\n')\n",
        "\n",
        "y1 = torch.matmul(tensor_one, tensor_two.T)\n",
        "y2 = tensor_one@tensor_two.T\n",
        "print(y1)\n",
        "print(y2, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IhpyFMeFOEO",
        "outputId": "efdecbea-70cd-40b3-95e2-a7dc41e80124"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5., 8., 6.],\n",
            "        [8., 4., 5.]], dtype=torch.float64, requires_grad=True)\n",
            "tensor([[-0.5961,  0.4550, -0.3670],\n",
            "        [ 0.7655,  0.6903, -0.0475]], dtype=torch.float64, requires_grad=True) \n",
            "\n",
            "tensor([[4.4039, 8.4550, 5.6330],\n",
            "        [8.7655, 4.6903, 4.9525]], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor([[4.4039, 8.4550, 5.6330],\n",
            "        [8.7655, 4.6903, 4.9525]], dtype=torch.float64, grad_fn=<AddBackward0>) \n",
            "\n",
            "tensor([[-2.9806,  3.6403, -2.2019],\n",
            "        [ 6.1236,  2.7612, -0.2377]], dtype=torch.float64,\n",
            "       grad_fn=<MulBackward0>)\n",
            "tensor([[-2.9806,  3.6403, -2.2019],\n",
            "        [ 6.1236,  2.7612, -0.2377]], dtype=torch.float64,\n",
            "       grad_fn=<MulBackward0>) \n",
            "\n",
            "tensor([[-1.5421,  9.0644],\n",
            "        [-4.7836,  8.6471]], dtype=torch.float64, grad_fn=<MmBackward0>)\n",
            "tensor([[-1.5421,  9.0644],\n",
            "        [-4.7836,  8.6471]], dtype=torch.float64, grad_fn=<MmBackward0>) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- requires_gra = True : tensor 연산할 때 gradient를 자동으로 tracking함\n",
        "- backward() : gradient 계산"
      ],
      "metadata": {
        "id": "iQdr4eyrGbt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([5], dtype=torch.float64, requires_grad=True)\n",
        "y = torch.tensor([2], dtype=torch.float64, requires_grad=True)\n",
        "z = x*y\n",
        "z.backward()\n",
        "print(x.grad)\n",
        "print(y.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2aO4GUaGDxQ",
        "outputId": "889ddc7d-d792-4e4a-d522-d3ffb5fc11e8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.], dtype=torch.float64)\n",
            "tensor([5.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- tensor -> numpy / numpy -> tensor를 했을 떄 tensor와 numpy arrat가 cpu에 있다면 메모리를 공유함"
      ],
      "metadata": {
        "id": "Mc-dwg9VHF-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")\n",
        "\n",
        "t.add_(3)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA8YD84hGuVJ",
        "outputId": "ac12532c-5d48-44d4-874f-257806300a65"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n",
            "t: tensor([4., 4., 4., 4., 4.])\n",
            "n: [4. 4. 4. 4. 4.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 메모리를 공유하기 때문에 3을 t에만 더했음에도 불구하고 n에도 더해짐\n",
        "\n",
        "\n",
        "- view -> tensor의 shape을 바꿔줌"
      ],
      "metadata": {
        "id": "YvTrse7aHYVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## torch.view\n",
        "x1 = torch.rand(4,5)\n",
        "x2 = x1.view(20)\n",
        "x3 = x1.view(2, -1) # 행은 2로 맞추고 열은 자동으로 맞춰주렴 -> 2행 10열\n",
        "x4 = x1.view(2,2,5)\n",
        "print(x1.shape)\n",
        "print(x2.shape)\n",
        "print(x3.shape)\n",
        "print(x4.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUY7L74rHWBj",
        "outputId": "c5de2359-f6bf-4c45-9a1c-cd00a7ddd7d4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 5])\n",
            "torch.Size([20])\n",
            "torch.Size([2, 10])\n",
            "torch.Size([2, 2, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- squeeze : tensor 차원 축소\n",
        "- unsqueeze : tensor 차원 확장"
      ],
      "metadata": {
        "id": "YYU1G-2dH7ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## squeeze\n",
        "x1 = torch.randn(3,1,1,3)\n",
        "print(x1, x1.shape)\n",
        "x2 = x1.squeeze()\n",
        "print(x2, x2.shape)\n",
        "print()\n",
        "\n",
        "## unsqueeze\n",
        "x1 = torch.randn(3,1,3)\n",
        "print(x1, x1.shape)\n",
        "x2 = x1.unsqueeze(dim=0)\n",
        "print(x2, x2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1uVGHfLHvjP",
        "outputId": "7c80fb35-9ec3-4b22-9089-797a9bd6cbc2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.7677,  1.5540, -1.1378]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9153, -0.6952,  0.6680]]],\n",
            "\n",
            "\n",
            "        [[[-1.2078, -2.1993, -0.8475]]]]) torch.Size([3, 1, 1, 3])\n",
            "tensor([[ 0.7677,  1.5540, -1.1378],\n",
            "        [ 0.9153, -0.6952,  0.6680],\n",
            "        [-1.2078, -2.1993, -0.8475]]) torch.Size([3, 3])\n",
            "\n",
            "tensor([[[-0.1341, -0.1238,  0.1845]],\n",
            "\n",
            "        [[-1.4993, -1.0174, -0.1276]],\n",
            "\n",
            "        [[-1.8016,  0.9480,  0.7419]]]) torch.Size([3, 1, 3])\n",
            "tensor([[[[-0.1341, -0.1238,  0.1845]],\n",
            "\n",
            "         [[-1.4993, -1.0174, -0.1276]],\n",
            "\n",
            "         [[-1.8016,  0.9480,  0.7419]]]]) torch.Size([1, 3, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- stack :새로운 차원으로 tensor를 붙임\n",
        "- cat : 주어진 차원에서 tensor를 붙임"
      ],
      "metadata": {
        "id": "9Ph3k4IZIq9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stack \n",
        "x1 = torch.randn([1,2,3])\n",
        "x2 = torch.randn([1,2,3])\n",
        "print('x1',x1, x1.shape)\n",
        "print('x2',x2, x2.shape)\n",
        "\n",
        "x3 = torch.stack([x1, x2])\n",
        "print('x3 stack',x3, x3.shape)\n",
        "x3 = torch.stack([x1, x2], dim=1)\n",
        "print('x3 dim1',x3, x3.shape)\n",
        "x3 = torch.stack([x1, x2], dim=2)\n",
        "print('x3 dim2',x3, x3.shape)\n",
        "x3 = torch.stack([x1, x2], dim=3)\n",
        "print('x3 dim3',x3, x3.shape)\n",
        "\n",
        "# cat\n",
        "x3 = torch.cat([x1, x2])\n",
        "print('x3 cat',x3, x3.shape)\n",
        "x3 = torch.cat([x1, x2], dim=1)\n",
        "print('x3 dim1',x3, x3.shape)\n",
        "x3 = torch.cat([x1, x2], dim=2)\n",
        "print('x3 dim2',x3, x3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pzhRBo0IMsq",
        "outputId": "2588564a-ae9a-49e2-ab59-16ca212cdfb7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x1 tensor([[[ 0.2458, -0.1800, -0.2299],\n",
            "         [-2.0637, -0.7763,  1.7518]]]) torch.Size([1, 2, 3])\n",
            "x2 tensor([[[ 1.2506, -0.4024, -0.6276],\n",
            "         [ 0.3515,  0.0759,  1.5524]]]) torch.Size([1, 2, 3])\n",
            "x3 stack tensor([[[[ 0.2458, -0.1800, -0.2299],\n",
            "          [-2.0637, -0.7763,  1.7518]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2506, -0.4024, -0.6276],\n",
            "          [ 0.3515,  0.0759,  1.5524]]]]) torch.Size([2, 1, 2, 3])\n",
            "x3 dim1 tensor([[[[ 0.2458, -0.1800, -0.2299],\n",
            "          [-2.0637, -0.7763,  1.7518]],\n",
            "\n",
            "         [[ 1.2506, -0.4024, -0.6276],\n",
            "          [ 0.3515,  0.0759,  1.5524]]]]) torch.Size([1, 2, 2, 3])\n",
            "x3 dim2 tensor([[[[ 0.2458, -0.1800, -0.2299],\n",
            "          [ 1.2506, -0.4024, -0.6276]],\n",
            "\n",
            "         [[-2.0637, -0.7763,  1.7518],\n",
            "          [ 0.3515,  0.0759,  1.5524]]]]) torch.Size([1, 2, 2, 3])\n",
            "x3 dim3 tensor([[[[ 0.2458,  1.2506],\n",
            "          [-0.1800, -0.4024],\n",
            "          [-0.2299, -0.6276]],\n",
            "\n",
            "         [[-2.0637,  0.3515],\n",
            "          [-0.7763,  0.0759],\n",
            "          [ 1.7518,  1.5524]]]]) torch.Size([1, 2, 3, 2])\n",
            "x3 cat tensor([[[ 0.2458, -0.1800, -0.2299],\n",
            "         [-2.0637, -0.7763,  1.7518]],\n",
            "\n",
            "        [[ 1.2506, -0.4024, -0.6276],\n",
            "         [ 0.3515,  0.0759,  1.5524]]]) torch.Size([2, 2, 3])\n",
            "x3 dim1 tensor([[[ 0.2458, -0.1800, -0.2299],\n",
            "         [-2.0637, -0.7763,  1.7518],\n",
            "         [ 1.2506, -0.4024, -0.6276],\n",
            "         [ 0.3515,  0.0759,  1.5524]]]) torch.Size([1, 4, 3])\n",
            "x3 dim2 tensor([[[ 0.2458, -0.1800, -0.2299,  1.2506, -0.4024, -0.6276],\n",
            "         [-2.0637, -0.7763,  1.7518,  0.3515,  0.0759,  1.5524]]]) torch.Size([1, 2, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- chunk : 주어진 차원 기준 tensor를 n개의 그룹으로 나눔 (n등분 50 / 10->5)\n",
        "- split : 주어진 차원 기준 tensor를 n개씩 구성된 그룹으로(n개씩 50 / 10->5)"
      ],
      "metadata": {
        "id": "N6oyopPgLvAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## chunk \n",
        "x1 = torch.stack([torch.ones(6), torch.zeros(6)], dim=0)\n",
        "print(x1, x1.shape)\n",
        "\n",
        "x2, x3 = torch.chunk(x1, 2, dim=0) # 행 기준 2개 그룹으로 나누기\n",
        "print(x2, x2.shape)\n",
        "print(x3, x3.shape)\n",
        "x2, x3 = torch.chunk(x1, 2, dim=1) # 열 기준 2개 그룹으로 나누기 \n",
        "print(x2, x2.shape)\n",
        "print(x3, x3.shape)\n",
        "\n",
        "## split\n",
        "x2, x3 = torch.split(x1, 1, dim=0) # 행 기준 한개씩 구성된 그룹으로 나누기\n",
        "print(x2, x2.shape)\n",
        "print(x3, x3.shape)\n",
        "x2, x3, x4 = torch.split(x1, 2, dim=1) # 열 기준 2개씩 구성된 그룹으로 나누기\n",
        "print(x2, x2.shape)\n",
        "print(x3, x3.shape)\n",
        "print(x4, x4.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zooc-qqVJh5J",
        "outputId": "a2e204a9-6a56-4603-fac7-349cdb477a82"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 0., 0.]]) torch.Size([2, 6])\n",
            "tensor([[1., 1., 1., 1., 1., 1.]]) torch.Size([1, 6])\n",
            "tensor([[0., 0., 0., 0., 0., 0.]]) torch.Size([1, 6])\n",
            "tensor([[1., 1., 1.],\n",
            "        [0., 0., 0.]]) torch.Size([2, 3])\n",
            "tensor([[1., 1., 1.],\n",
            "        [0., 0., 0.]]) torch.Size([2, 3])\n",
            "tensor([[1., 1., 1., 1., 1., 1.]]) torch.Size([1, 6])\n",
            "tensor([[0., 0., 0., 0., 0., 0.]]) torch.Size([1, 6])\n",
            "tensor([[1., 1.],\n",
            "        [0., 0.]]) torch.Size([2, 2])\n",
            "tensor([[1., 1.],\n",
            "        [0., 0.]]) torch.Size([2, 2])\n",
            "tensor([[1., 1.],\n",
            "        [0., 0.]]) torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- tensor를 gpu로 이동"
      ],
      "metadata": {
        "id": "RrMUqlqvM_bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.randn(2,3)\n",
        "print(x1)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "x1 = x1.to(device)\n",
        "x2 = torch.randn(2,3, device=device)\n",
        "x3 = torch.randn(2,3)\n",
        "print(x1+x2)\n",
        "print(x1+x3) # 하나는 gpu, 하나는 cpu에 있기 때문에 에러 발생"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "CbXDrm1kMTLq",
        "outputId": "40f65e71-a964-4f40-d744-ea43371fbf35"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1086,  0.2151,  0.6767],\n",
            "        [ 0.6765,  0.7856, -1.7748]])\n",
            "cuda\n",
            "tensor([[ 0.0084,  1.2331,  1.4985],\n",
            "        [ 1.1303, -0.2185, -0.7794]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-f091f4d1dfcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oYAwYxL9NPgd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}